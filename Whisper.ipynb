{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-tvmcj62_\n",
      "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-tvmcj62_\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from whisper==1.0) (4.2.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.1 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.3 MB 867 bytes/s  0:00:011   |▏                               | 3.9 MB 31.3 MB/s eta 0:00:25     |▉                               | 21.0 MB 31.3 MB/s eta 0:00:25     |█▍                              | 33.4 MB 17.4 MB/s eta 0:00:43     |████████▊                       | 210.3 MB 16.9 MB/s eta 0:00:34     |███████████▍                    | 275.3 MB 14.0 MB/s eta 0:00:36     |██████████████▎                 | 347.6 MB 8.2 MB/s eta 0:00:52     |██████████████▉                 | 359.9 MB 10.1 MB/s eta 0:00:42     |████████████████▊               | 406.5 MB 6.4 MB/s eta 0:00:58     |██████████████████████████████  | 726.0 MB 9.2 MB/s eta 0:00:06     |██████████████████████████████▉ | 749.2 MB 472 kB/s eta 0:00:58��████ | 749.5 MB 472 kB/s eta 0:00:57\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 9.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting transformers>=4.19.0\n",
      "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.9.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "\u001b[K     |████████████████████████████████| 772 kB 23.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "\u001b[K     |████████████████████████████████| 163 kB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 15.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers>=4.19.0->whisper==1.0) (5.3.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tgraupmann/.local/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.22.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/tgraupmann/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
      "Building wheels for collected packages: whisper, future\n",
      "  Building wheel for whisper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175206 sha256=aee03e92a30bd55b3d1230d04fea37d63e6477aeb01c6298651a1f4fa442e0da\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8o71mors/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=20373a31d393efd05f887b759aa59811818b417eb492e6e729380ddd2e52af15\n",
      "  Stored in directory: /home/tgraupmann/.cache/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built whisper future\n",
      "Installing collected packages: future, ffmpeg-python, numpy, typing-extensions, torch, tqdm, regex, huggingface-hub, tokenizers, transformers, whisper\n",
      "\u001b[33m  WARNING: The scripts futurize and pasteurize are installed in '/home/tgraupmann/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.8 are installed in '/home/tgraupmann/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/tgraupmann/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/home/tgraupmann/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/tgraupmann/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/tgraupmann/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script whisper is installed in '/home/tgraupmann/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed ffmpeg-python-0.2.0 future-0.18.2 huggingface-hub-0.10.1 numpy-1.23.4 regex-2022.9.13 tokenizers-0.13.1 torch-1.12.1 tqdm-4.64.1 transformers-4.23.1 typing-extensions-4.4.0 whisper-1.0\n"
     ]
    }
   ],
   "source": [
    "# Increase VM size to at least 12GB\n",
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:15<00:00, 9.33MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' This file uses the WAVE file format.',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 4.0,\n",
       "   'text': ' This file uses the WAVE file format.',\n",
       "   'tokens': [50364, 639, 3991, 4960, 264, 26915, 7540, 3991, 7877, 13, 50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4660278558731079,\n",
       "   'compression_ratio': 0.9,\n",
       "   'no_speech_prob': 0.012060215696692467}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.transcribe(\"Test_WAV.wav\", language=\"en\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' This file uses the MP3 file format.',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 4.0,\n",
       "   'text': ' This file uses the MP3 file format.',\n",
       "   'tokens': [50364, 639, 3991, 4960, 264, 14146, 18, 3991, 7877, 13, 50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3831677834192912,\n",
       "   'compression_ratio': 0.8974358974358975,\n",
       "   'no_speech_prob': 0.01380200870335102}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.transcribe(\"Test_MP3.mp3\", language=\"en\")\n",
    "out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "dfac69366e7610d1b9edf3914f459e5ae6a7ea624b6887f7f098682edd048f82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
