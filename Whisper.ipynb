{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-e1rbclxc\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-e1rbclxc\n",
      "  Resolved https://github.com/openai/whisper.git to commit 9f70a352f9f8630ab3aa0d06af5cb9532bd8c21d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from whisper==1.0) (1.21.5)\n",
      "Requirement already satisfied: torch in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from whisper==1.0) (1.12.1)\n",
      "Requirement already satisfied: tqdm in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from whisper==1.0) (4.64.1)\n",
      "Requirement already satisfied: more-itertools in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from whisper==1.0) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.19.0 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from whisper==1.0) (4.23.1)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from whisper==1.0) (0.2.0)\n",
      "Requirement already satisfied: future in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\n",
      "Requirement already satisfied: filelock in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (3.6.0)\n",
      "Requirement already satisfied: requests in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (0.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from torch->whisper==1.0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/tgraupmann/anaconda3/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "# Increase VM size to at least 12GB\n",
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "#model = whisper.load_model(\"tiny\")\n",
    "model = whisper.load_model(\"base\") #max size supported by Samsung ChromeBook4 with 4GB of RAM\n",
    "#model = whisper.load_model(\"small\")\n",
    "#model = whisper.load_model(\"medium\")\n",
    "#model = whisper.load_model(\"large\") # too large for my PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tgraupmann/anaconda3/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': ' This file uses the WAVE file format.',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 4.0,\n",
       "   'text': ' This file uses the WAVE file format.',\n",
       "   'tokens': [50364, 639, 3991, 4960, 264, 26915, 7540, 3991, 7877, 13, 50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4650975465774536,\n",
       "   'compression_ratio': 0.9,\n",
       "   'no_speech_prob': 0.012118643149733543}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.transcribe(\"Test_WAV.wav\", language=\"en\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tgraupmann/anaconda3/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': ' This file uses the MP3 file format.',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 4.0,\n",
       "   'text': ' This file uses the MP3 file format.',\n",
       "   'tokens': [50364, 639, 3991, 4960, 264, 14146, 18, 3991, 7877, 13, 50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3829184373219808,\n",
       "   'compression_ratio': 0.8974358974358975,\n",
       "   'no_speech_prob': 0.0137099027633667}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.transcribe(\"Test_MP3.mp3\", language=\"en\")\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tgraupmann/anaconda3/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \" Okay, here we go. I'm gonna read the script you gave me by using Mandarin Chinese. Okay, now we're going to Wendels, the blue one. What are you actually doing? Are you using Wendels? Do you have a lot of games on Steam? You choose the color selection and the color selection. Try and use Hey Evan Hagstamer, and you may often see him легко.\",\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 7.0,\n",
       "   'text': \" Okay, here we go. I'm gonna read the script you gave me by using Mandarin Chinese.\",\n",
       "   'tokens': [50364,\n",
       "    1033,\n",
       "    11,\n",
       "    510,\n",
       "    321,\n",
       "    352,\n",
       "    13,\n",
       "    286,\n",
       "    478,\n",
       "    799,\n",
       "    1401,\n",
       "    264,\n",
       "    5755,\n",
       "    291,\n",
       "    2729,\n",
       "    385,\n",
       "    538,\n",
       "    1228,\n",
       "    42292,\n",
       "    4649,\n",
       "    13,\n",
       "    50714,\n",
       "    50714],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4616202116012573,\n",
       "   'compression_ratio': 1.0,\n",
       "   'no_speech_prob': 0.1694246232509613},\n",
       "  {'id': 1,\n",
       "   'seek': 700,\n",
       "   'start': 7.0,\n",
       "   'end': 21.0,\n",
       "   'text': \" Okay, now we're going to Wendels, the blue one. What are you actually doing? Are you using Wendels?\",\n",
       "   'tokens': [50364,\n",
       "    1033,\n",
       "    11,\n",
       "    586,\n",
       "    321,\n",
       "    434,\n",
       "    516,\n",
       "    281,\n",
       "    343,\n",
       "    521,\n",
       "    1625,\n",
       "    11,\n",
       "    264,\n",
       "    3344,\n",
       "    472,\n",
       "    13,\n",
       "    708,\n",
       "    366,\n",
       "    291,\n",
       "    767,\n",
       "    884,\n",
       "    30,\n",
       "    2014,\n",
       "    291,\n",
       "    1228,\n",
       "    343,\n",
       "    521,\n",
       "    1625,\n",
       "    30,\n",
       "    51064,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.8665079474449158,\n",
       "   'compression_ratio': 1.125,\n",
       "   'no_speech_prob': 0.04264684021472931},\n",
       "  {'id': 2,\n",
       "   'seek': 2100,\n",
       "   'start': 21.0,\n",
       "   'end': 35.0,\n",
       "   'text': ' Do you have a lot of games on Steam? You choose the color selection and the color selection.',\n",
       "   'tokens': [50364,\n",
       "    1144,\n",
       "    291,\n",
       "    362,\n",
       "    257,\n",
       "    688,\n",
       "    295,\n",
       "    2813,\n",
       "    322,\n",
       "    22517,\n",
       "    30,\n",
       "    509,\n",
       "    2826,\n",
       "    264,\n",
       "    2017,\n",
       "    9450,\n",
       "    293,\n",
       "    264,\n",
       "    2017,\n",
       "    9450,\n",
       "    13,\n",
       "    51064,\n",
       "    51064],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.9333952267964681,\n",
       "   'compression_ratio': 1.1948051948051948,\n",
       "   'no_speech_prob': 0.004343927372246981},\n",
       "  {'id': 3,\n",
       "   'seek': 3500,\n",
       "   'start': 35.0,\n",
       "   'end': 62.0,\n",
       "   'text': ' Try and use Hey Evan Hagstamer, and you may often see him легко.',\n",
       "   'tokens': [50364,\n",
       "    6526,\n",
       "    293,\n",
       "    764,\n",
       "    1911,\n",
       "    22613,\n",
       "    389,\n",
       "    559,\n",
       "    372,\n",
       "    13530,\n",
       "    11,\n",
       "    293,\n",
       "    291,\n",
       "    815,\n",
       "    2049,\n",
       "    536,\n",
       "    796,\n",
       "    39995,\n",
       "    13,\n",
       "    51714,\n",
       "    51714],\n",
       "   'temperature': 1.0,\n",
       "   'avg_logprob': -3.8844372142444956,\n",
       "   'compression_ratio': 0.8533333333333334,\n",
       "   'no_speech_prob': 0.0008523261058144271}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.transcribe(\"Test_Chinese.mp3\", language=\"en\")\n",
    "out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
